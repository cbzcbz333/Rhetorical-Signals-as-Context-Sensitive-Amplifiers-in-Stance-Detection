(.venv) PS C:\Users\27981\PycharmProjects\lichang> python -m neural.run_neural   --train data/train.jsonl --dev data/validation.jsonl   --model_type N1 --backbone bert-base-uncased --num_labels 3   --bs 4 --max_len 64 --epochs 1

C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\transformers\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  step=50/655 loss=0.8743
  step=100/655 loss=1.1376
  step=150/655 loss=0.8966
  step=200/655 loss=0.8656
  step=250/655 loss=1.2754
  step=300/655 loss=0.8531
  step=350/655 loss=0.7900
  step=400/655 loss=0.8036
  step=450/655 loss=0.4925
  step=500/655 loss=0.3843
  step=550/655 loss=1.2133
  step=600/655 loss=0.8361
  step=650/655 loss=0.7268
epoch=1 loss=0.9137 dev_acc=0.6497 dev_f1=0.6188 ✅ best

Best dev_f1=0.6188 saved to: ../checkpoints\best_N1_bert-base-uncased.pt


(.venv) PS C:\Users\27981\PycharmProjects\lichang> python -m neural.run_neural   --train data/train.jsonl   --dev data/validation.jsonl   --test data/test.jsonl   --model_type N2   --backbone bert-base-uncased   --num_labels 3
 --rf_path data/rhetoric_features_all0113addcon2.jsonl   --rf_dim 10   --bs 4   --max_len 64   --epochs 1
C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\transformers\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  step=50/655 loss=1.2907
  step=100/655 loss=0.7047
  step=150/655 loss=0.8480
  step=200/655 loss=1.1964
  step=250/655 loss=0.8041
  step=300/655 loss=0.9741
  step=350/655 loss=0.6307
  step=400/655 loss=0.8346
  step=450/655 loss=0.6432
  step=500/655 loss=0.9946
  step=550/655 loss=0.7224
  step=600/655 loss=0.7454
  step=650/655 loss=0.5393
epoch=1 loss=0.9175 dev_acc=0.6497 dev_f1=0.6292 ✅ best

Best dev_f1=0.6292 saved to: ../checkpoints\best_N2_bert-base-uncased.pt
C:\Users\27981\PycharmProjects\lichang\neural\run_neural.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to
construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `we
ights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user
 via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(best_path, map_location=device)

Loaded best checkpoint (epoch=1, dev_f1=0.6292)
TEST  acc=0.6597  macro_f1=0.6201

(.venv) PS C:\Users\27981\PycharmProjects\lichang> python -m neural.run_neural   --train data/train.jsonl   --dev data/validation.jsonl   --test data/test.jsonl   --model_type N1  --backbone bert-base-uncased   --num_labels 3   --bs 4   --max_len 64   --epochs 1
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 49b839d0-a6c9-4a53-97db-67021dca874b)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 1s [Retry 1/5].
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 2a908746-a651-46e5-bb8f-cd2edf184894)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 2s [Retry 2/5].
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 1d3457e7-746d-4193-bd98-e16c5a017b10)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 4s [Retry 3/5].
C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\transformers\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  step=50/655 loss=1.3824
  step=100/655 loss=0.8222
  step=150/655 loss=0.9212
  step=200/655 loss=1.6460
  step=250/655 loss=1.5931
  step=300/655 loss=0.5671
  step=350/655 loss=0.2079
  step=400/655 loss=1.6427
  step=450/655 loss=0.6404
  step=500/655 loss=0.9070
  step=550/655 loss=0.9353
  step=600/655 loss=0.4071
  step=650/655 loss=1.1575
epoch=1 loss=0.8810 dev_acc=0.6327 dev_f1=0.6148 ✅ best

Best dev_f1=0.6148 saved to: ../checkpoints\best_N1_bert-base-uncased.pt
C:\Users\27981\PycharmProjects\lichang\neural\run_neural.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to
construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `we
ights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user
 via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(best_path, map_location=device)

Loaded best checkpoint (epoch=1, dev_f1=0.6148)
TEST  acc=0.6413  macro_f1=0.6140

(.venv) PS C:\Users\27981\PycharmProjects\lichang> python -m neural.run_neural   --train data/train.jsonl   --dev data/validation.jsonl   --test data/test.jsonl   --model_type N1
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 9bbb0ced-d0d2-4847-a256-62a6a1b99d6d)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 1s [Retry 1/5].
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 8e2f4b96-2637-4f71-bde8-e4d3e1a030ef)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 2s [Retry 2/5].
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 5cffc487-04be-430d-88c8-6f543b5f66f1)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 4s [Retry 3/5].
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 9e242ed2-f62e-4c93-ab08-c74a6383fbec)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 8s [Retry 4/5].
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: c456cede-584a-4511-838d-d8560fbb1395)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 8s [Retry 5/5].
Traceback (most recent call last):
  File "C:\Users\27981\AppData\Local\Programs\Python\Python38\lib\runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "C:\Users\27981\AppData\Local\Programs\Python\Python38\lib\runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "C:\Users\27981\PycharmProjects\lichang\neural\run_neural.py", line 110, in <module>
    main()
  File "C:\Users\27981\PycharmProjects\lichang\neural\run_neural.py", line 34, in main
    train_ds = StanceDataset(args.train, args.backbone, args.max_len,
  File "C:\Users\27981\PycharmProjects\lichang\neural\datasets.py", line 34, in __init__
    self.tok = AutoTokenizer.from_pretrained(tokenizer_name, use_fast=True)
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 857, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 689, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\transformers\utils\hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\huggingface_hub\file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\huggingface_hub\file_download.py", line 1070, in _hf_hub_download_to_cache_dir
    (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = _get_metadata_or_catch_error(
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\huggingface_hub\file_download.py", line 1543, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\huggingface_hub\file_download.py", line 1460, in get_hf_file_metadata
    r = _request_wrapper(
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\huggingface_hub\file_download.py", line 283, in _request_wrapper
    response = _request_wrapper(
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\huggingface_hub\file_download.py", line 306, in _request_wrapper
    response = http_backoff(method=method, url=url, **params)
  File "C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\huggingface_hub\utils\_http.py", line 329, in http_backoff
    time.sleep(sleep_time)
KeyboardInterrupt
(.venv) PS C:\Users\27981\PycharmProjects\lichang> python -m neural.run_neural   --train data/train.jsonl   --dev data/validation.jsonl   --test data/test.jsonl   --model_type N1  --backbone bert-base-uncased   --num_labels 3   --bs 4   --max_len 64   --epochs 1
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 49b839d0-a6c9-4a53-97db-67021dca874b)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 1s [Retry 1/5].
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 2a908746-a651-46e5-bb8f-cd2edf184894)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 2s [Retry 2/5].
'(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))"), '(Request ID: 1d3457e7-746d-4193-bd98-e16c5a017b10)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json
Retrying in 4s [Retry 3/5].
C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\transformers\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  step=50/655 loss=1.3824
  step=100/655 loss=0.8222
  step=150/655 loss=0.9212
  step=200/655 loss=1.6460
  step=250/655 loss=1.5931
  step=300/655 loss=0.5671
  step=350/655 loss=0.2079
  step=400/655 loss=1.6427
  step=450/655 loss=0.6404
  step=500/655 loss=0.9070
  step=550/655 loss=0.9353
  step=600/655 loss=0.4071
  step=650/655 loss=1.1575
epoch=1 loss=0.8810 dev_acc=0.6327 dev_f1=0.6148 ✅ best
  step=650/655 loss=1.1575
epoch=1 loss=0.8810 dev_acc=0.6327 dev_f1=0.6148 ✅ best

Best dev_f1=0.6148 saved to: ../checkpoints\best_N1_bert-base-uncased.pt
C:\Users\27981\PycharmProjects\lichang\neural\run_neural.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(best_path, map_location=device)

Loaded best checkpoint (epoch=1, dev_f1=0.6148)
TEST  acc=0.6413  macro_f1=0.6140
(.venv) PS C:\Users\27981\PycharmProjects\lichang> python -m neural.run_neural   --train data/train.jsonl --dev data/validation.jsonl --test data/test.jsonl   --model_type N1 --backbone bert-base-uncased --num_labels 3   --bs 8 --max_len 96 --epochs 3
C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\transformers\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  step=50/328 loss=1.0330
  step=100/328 loss=0.8907
  step=150/328 loss=0.7928
  step=200/328 loss=0.7721
  step=250/328 loss=1.2162
  step=300/328 loss=0.9098
epoch=1 loss=0.9395 dev_acc=0.6531 dev_f1=0.6265 ✅ best
  step=50/328 loss=0.2983
  step=100/328 loss=0.7912
  step=150/328 loss=0.7140
  step=200/328 loss=0.2477
  step=250/328 loss=1.0366
  step=300/328 loss=0.7060
epoch=2 loss=0.6367 dev_acc=0.6803 dev_f1=0.6492 ✅ best
  step=50/328 loss=0.3080
  step=100/328 loss=0.8910
  step=150/328 loss=0.1950
  step=200/328 loss=0.3700
  step=250/328 loss=1.0371
  step=300/328 loss=0.3829
epoch=3 loss=0.3854 dev_acc=0.7041 dev_f1=0.6919 ✅ best

Best dev_f1=0.6919 saved to: ../checkpoints\best_N1_bert-base-uncased.pt
C:\Users\27981\PycharmProjects\lichang\neural\run_neural.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which u
ses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/
pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limi
ts the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted
 by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(best_path, map_location=device)

Loaded best checkpoint (epoch=3, dev_f1=0.6919)
TEST  acc=0.6685  macro_f1=0.6377

(.venv) PS C:\Users\27981\PycharmProjects\lichang> python -m neural.run_neural   --train data/train.jsonl --dev data/validation.jsonl --test data/test.jsonl   --model_type N2 --backbone bert-base-uncased --num_labels 3   --rf_path data/rhetoric_features_all0113addcon2.jsonl --rf_dim 10   --bs 8 --max_len 96 --epochs 3
C:\Users\27981\PycharmProjects\lichang\.venv\lib\site-packages\transformers\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  step=50/328 loss=1.3130
  step=100/328 loss=0.6450
  step=150/328 loss=0.9202
  step=200/328 loss=1.0186
  step=250/328 loss=0.6604
  step=300/328 loss=1.2323
epoch=1 loss=0.9358 dev_acc=0.5850 dev_f1=0.5637 ✅ best
  step=50/328 loss=0.5706
  step=100/328 loss=0.3773
  step=150/328 loss=0.1767
  step=200/328 loss=0.3801
  step=250/328 loss=0.4106
  step=300/328 loss=0.4030
epoch=2 loss=0.6170 dev_acc=0.6871 dev_f1=0.6796 ✅ best
  step=50/328 loss=0.2181
  step=100/328 loss=0.3344
  step=150/328 loss=0.0861
  step=200/328 loss=0.4966
  step=250/328 loss=0.1685
  step=300/328 loss=0.5097
epoch=3 loss=0.3603 dev_acc=0.6803 dev_f1=0.6717

Best dev_f1=0.6796 saved to: ../checkpoints\best_N2_bert-base-uncased.pt
C:\Users\27981\PycharmProjects\lichang\neural\run_neural.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which u
ses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/
pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limi
ts the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted
 by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(best_path, map_location=device)

Loaded best checkpoint (epoch=2, dev_f1=0.6796)
TEST  acc=0.6717  macro_f1=0.6385
